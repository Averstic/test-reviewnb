{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"2021 soy agriplex marker assessment\"\n",
    "author: \"Zachary H. Lemmon\"\n",
    "affiliation: \"Inari Agriculture\"\n",
    "date: \"7/8/2021\"\n",
    "output:\n",
    "  html_document:\n",
    "      toc: true\n",
    "          toc_depth: 3\n",
    "\t      toc_float: true\n",
    "\t      ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "echo": "FALSE",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "crosses = read.table('../data/s1_crosses.txt', header=TRUE, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the 2021 field season there are `r sum(crosses$Number.of.Lines.in.21NAS_SB_SS)` soybean S1 individuals (across `r sum(crosses$Number.of.Lines.in.21NAS_SB_SS>0)` populations) that were planted and will be selected for advancement in the fall of 2021. There is an interest in using genomic prediction (GP) methods to assess the performance of S1 lines before the end of the field season, but in order to run GP on these plants we need a genotyping assay that will provide a reasonable number of segregating markers at a reasonable price point. To accomplish this genotyping need for Inari's 2021 S1 lines, we are investigating the AgriPlex developed panel of SNP markers for soybean. These markers largely are included in the 6k soybean SNPchip (that we used to genotype our other soybean germplasm). There are a few additional markers that were included in the Agriplex SNP panel that appear to have come from the public sector collaborators to track specific traits, these SNPs have potential value in future trait introgression (TI) work. \n",
    "\n",
    "## Purpose\n",
    "\n",
    "Assess the suitability of the pre-made Agriplex SNP genotyping panel for our current 2021 field season crop of soybean S1 lines in development. This assessment will be done *in silico* leveraging existing line genotypes registered in the Inari vcf-services to infer expected segregation patterns (SNP identity, number, and genomic distribution). \n",
    "\n",
    "## Data and Links\n",
    "\n",
    "Input data will be stored via DAD, analysis code on github. You will also need to set up VCF service/credentials and a few conda environments which are again documented in the DAD archive and in the Rmd notebook.\n",
    "\n",
    "- DAD: `zhl-analyses/darp-20210708_soy_agriplex_marker_assessment_data`\n",
    "  - github: `https://github.com/inari-ag/darp-20210708_soy_agriplex_marker_assessment`\n",
    "      - branch: `initial-commit`\n",
    "\n",
    "## Results and Conclusions\n",
    "\n",
    "### Results\n",
    "\n",
    "Key files displaying these results can be found in the `../res/` directory\n",
    "\n",
    "- All inbred lines of interest have genotype data\n",
    "  - Average SNPs per chromosome per cross is ~20\n",
    "    - Average total SNPs per cross is ~400\n",
    "      - Distribution of SNPs is not entirely even and we do have gaps across the chromosomes\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "About a third of the markers (~400) are informative in any given S1 population (founding cross). This means that genomic prediction will be operating on an average of ~400 SNPs per population using the premade Agriplex SNP assay panel. Previous work has shown that ~1000-1500 markers is optimal for achieving maximum prediction accuracy in corn, but we do not have a comparable study in soybean and building a 1000-1500 marker panel for soybean would be cost prohibitive. In fall of 2020 we did see reasonable prediction accuracies for our corn S1/2 populations where we only had ~200 segregating sites per cross. Consequently, moving forward with the premade Agriplex SNP panel looks like a viable genotyping strategy at least for the 2021 soybean S1 populations.\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial data pull\n",
    "\n",
    "If you do not have it, you will need to pull the above listed DAD tag to the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "engine.opts": "'-l'",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "# This will latch onto the .dad file within the data/ directory pulled from github. If not you may need to manually specify the project and tag listed above.\n",
    "# dad pull ../data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steal previously mapped soybean 6k marker SNPs from the xlsx-to-vcf docker image on ECR\n",
    "docker run --rm \\\n",
    "  -v $PWD/../data:/app/data \\\n",
    "    335777049998.dkr.ecr.us-east-1.amazonaws.com/xlsx-to-vcf:1.0.3 \\\n",
    "        awk 'BEGIN{FS=\"\\t\"; OFS=\"\\t\"}FNR==NR{idarr[$2]=$1; posarr[$2]=$3; next}{if($2 in idarr){print idarr[$2], $0}}' data/snps.txt xlsx_to_vcf/data/gnm1_to_gnm4_with_ssNumber.txt > data/gnm4_snps.txt\n",
    "\tawk 'BEGIN{FS=\"\\t\"; OFS=\"\\t\"}FNR==NR{arr[$1]=$0; next}{print $0, arr[$3]}' ../data/6k_snps.txt data/gnm4_snps.txt > ../data/merged_6k_agriplex.txt\n",
    "\t# Some stats\n",
    "\tawk 'BEGIN{FS=\"\\t\"; OFS=\"\\t\"}{print NF}' ../data/merged_6k_agriplex.txt | sort -k1,1n | uniq -c\n",
    "\t```\n",
    "\n",
    "### VCF service query\n",
    "\n",
    "```{bash query_vcf}\n",
    "# API_SERVER_BASE_URL required to query vcf-services. Make sure you setup the appropriate variables for where you are.\n",
    "echo ${API_SERVER_BASE_URL}\n",
    "# Query the vcf-services for a specific soybean genotype file\n",
    "docker run --rm \\\n",
    "  -v $HOME/.aws:/root/.aws:ro \\\n",
    "    -v $PWD/../vcf-service-working:/tmp \\\n",
    "      -e API_SERVER_BASE_URL=${API_SERVER_BASE_URL} \\\n",
    "        335777049998.dkr.ecr.us-east-1.amazonaws.com/vcf-services-client:master \\\n",
    "\t    python3 scripts/multi_sample_query.py --name_filter \"= 'soybean-inari-without-duplicate-cultivars-20210121.vcf.gz'\"\n",
    "\t    ```\n",
    "\n",
    "### Fetch soybean VCF\n",
    "\n",
    "```{bash fetch_files, engine.opts='-l'}\n",
    "# Turn on my base conda env and document the contents\n",
    "conda activate base\n",
    "conda env export > ../data/base_conda.yaml\n",
    "cat ../data/base_conda.yaml\n",
    "# Pull the vcf-services registered ID and pull from AWS\n",
    "ID=$(jq -r '.[].id' ../vcf-service-working/multi_sample_query.json)\n",
    "echo ${ID}\n",
    "aws s3 cp --recursive --exclude \"*\" --include \"*${ID}*\" s3://inari-vcf-service ../vcf-out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VCF metadata pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull metadata\n",
    "MDT=`find ../vcf-out -name \"*json\"`\n",
    "MDT=`basename ${MDT}`\n",
    "LOOKUP=${MDT/json/lookup.json}\n",
    "docker run --rm \\\n",
    "        -v $HOME/.aws:/root/.aws \\\n",
    "\t        -v $PWD/../vcf-out:/app/out \\\n",
    "\t\t        -e API_SERVER_BASE_URL=${API_SERVER_BASE_URL} \\\n",
    "\t\t\t        --entrypoint python3 \\\n",
    "\t\t\t\t        335777049998.dkr.ecr.us-east-1.amazonaws.com/vcf-services-client:master \\\n",
    "\t\t\t\t\t        scripts/multisample_mdt_reverse_lookup.py \\\n",
    "\t\t\t\t\t\t                --metadata_file out/poc/mdt/multi-sample/${MDT} \\\n",
    "\t\t\t\t\t\t\t\t                --output_file out/poc/mdt/multi-sample/${LOOKUP} > /dev/null 2>&1\n",
    "\t\t\t\t\t\t\t\t\t\t```\n",
    "\n",
    "### VCF meta shaping\n",
    "\n",
    "```{r read_meta}\n",
    "library(rjson)\n",
    "meta=fromJSON(file='../vcf-out/poc/mdt/multi-sample/soybean-inari-without-duplicate-cultivars-20210121-523c7cda047f43ddb5cd949fae80c8e7-metadata.lookup.json')\n",
    "cultivar = lapply(lapply(meta[['sample_metadata']], '[[', 2), '[[', 5)\n",
    "assay = lapply(lapply(meta[['sample_metadata']], '[[', 2), '[[', 6)\n",
    "sampld_id = lapply(lapply(meta[['sample_metadata']], '[[', 2), '[[', 7)\n",
    "sample_name = lapply(lapply(meta[['sample_metadata']], '[[', 2), '[[', 8)\n",
    "source = lapply(lapply(meta[['sample_metadata']], '[[', 2), '[[', 2)\n",
    "field_season = lapply(lapply(meta[['sample_metadata']], '[[', 2), '[[', 3)\n",
    "meta.frame = data.frame(sample_name=unlist(sample_name), \n",
    "\t\t\t                        cultivar=unlist(cultivar), \n",
    "\t\t\t\t\t\t                        source=unlist(source), \n",
    "\t\t\t\t\t\t                        field_season=unlist(field_season),\n",
    "\t\t\t\t\t\t\t\t\t                        assay=unlist(assay))\n",
    "genames = read.table('../data/gename_cultivar.txt', header = TRUE, sep = '\\t')\n",
    "meta.frame$gename = genames[match(meta.frame$cultivar, genames$Inbred_Name), 'GE_NAME']\n",
    "head(meta.frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parents = read.table('../data/parents.txt', sep = '\\t', header=TRUE)\n",
    "# Want to add in the recurrent parents for edit TI, donor is NINF1170 for the edits\n",
    "RPs = c('HUNE1430', 'RANF1335', 'TENF1362', 'TENG1686', 'TENC1559', 'TENE1516', 'TENG1501', 'GINF9586', 'GINF9707', 'GINE9013')\n",
    "parents_RPs = c(parents$Founding.Parents, RPs[!RPs %in% parents$Founding.Parents])\n",
    "sum(duplicated(parents_RPs))  # non are duplicated\n",
    "# How many of the founding parents exist in the meta.frame?\n",
    "sum(parents$Founding.Parents %in% meta.frame$gename) / nrow(parents)\n",
    "# How many of the RPs in the meta.frame?\n",
    "sum(RPs %in% meta.frame$gename) / length(RPs)\n",
    "# All of them, we have all data. Let's substitute samplenames for genames in the next chunk after we export the samplename\\tgename frame\n",
    "# Any duplicated genames? Will need to uniquify\n",
    "sum(duplicated(meta.frame$gename))  # no duplicated genames so just go with the straight gename\n",
    "# rehead_frame = cbind(meta.frame[, c('sample_name')], apply(meta.frame[, c('gename', 'field_season')], 1, FUN = function(x){paste(x, collapse=':')}))\n",
    "rehead_frame = meta.frame[, c('sample_name', 'gename')]\n",
    "# Any duplicated sample names?\n",
    "sum(duplicated(rehead_frame[, 2]))  # nope we're good\n",
    "write.table(x=rehead_frame, file='../data/reheader.txt', quote = FALSE, sep = \"\\t\", row.names = FALSE, col.names = FALSE)\n",
    "# Write out the parents+RPs to file for sample subsetting later\n",
    "write.table(x=parents_RPs, file='../data/parents_rps.txt', quote=FALSE, row.names=FALSE, col.names=FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reheader VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "engine.opts": "'-l'",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "#Activate and document the samtools conda environment\n",
    "conda activate samtools\n",
    "conda env export > ../data/samtools_env.yaml\n",
    "cat ../data/samtools_env.yaml\n",
    "# Find the vcf and use it\n",
    "VCF=$(find ../vcf-out -name \"*soybean-inari-without-duplicate-cultivars-20210121-523c7cda047f43ddb5cd949fae80c8e7.vcf.gz\")\n",
    "OUTVCF=${VCF/.vcf.gz/_reheader_subset.vcf.gz}\n",
    "bcftools reheader --samples ../data/reheader.txt ${VCF} | bcftools view --samples-file ../data/parents_rps.txt -Oz -o ${OUTVCF}\n",
    "tabix -f ${OUTVCF}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *in silico* cross construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "engine.opts": "'-l'",
     "id": ""
    }
   },
   "outputs": [],
   "source": [
    "# Activate samtools conda environment again\n",
    "conda activate samtools\n",
    "# Parse each cross combination into a phased genotype call, convert hets to missing.\n",
    "cut -f4,5 -d$'\\t' ../data/gnm4_snps.txt | sort -k1,1 -k2,2n > ../data/gnm4_subset_snps.txt\n",
    "VCF=$(find ../vcf-out -name \"*_reheader_subset.vcf.gz\")\n",
    "mkdir -p ../data/cross_genotypes\n",
    "while read XD P1_P2 REST; do\n",
    "        if [[ ${P1_P2} == 'Pedigree' ]]; then continue; fi\n",
    "\t        P1=${P1_P2/\\/*}\n",
    "\t\t        P2=${P1_P2/*\\/}\n",
    "\t\t\t        # echo ${P1} ${P2}\n",
    "\t\t\t\t        bcftools view --samples \"${P1},${P2}\" --regions-file ../data/gnm4_subset_snps.txt ${VCF} | sed -e 's/0\\/1/./g' -e 's/\\.\\/\\././g' | bcftools query -f \"%CHROM\\t%POS\\t%REF\\t%ALT[\\t%GT]\\n\" - | awk -v P1=${P1} -v P2=${P2} 'BEGIN{printf(\"CHROM\\tPOS\\tREF\\tALT\\t%s|%s\\n\", P1, P2)}{gsub(/\\/[01]/, \"\", $5); gsub(/\\/[01]/, \"\", $6); printf(\"%s\\t%s\\t%s\\t%s\\t%s|%s\\n\", $1, $2, $3, $4, $5, $6)}' > ../data/cross_genotypes/${P1}_${P2}.txt\n",
    "\t\t\t\t\tdone < ../data/s1_crosses.txt\n",
    "\t\t\t\t\t# Let's merge all the individual files\n",
    "\t\t\t\t\tpaste ../data/cross_genotypes/*txt | awk '{printf(\"%s\\t%s\\t%s\\t%s\", $1, $2, $3, $4); for(i=5; i<=NF; i=i+5){printf(\"\\t%s\", $i)} printf(\"\\n\")}' > ../data/phased_cross_genotypes.txt\n",
    "\t\t\t\t\t# Let's try and summarize a bit\n",
    "\t\t\t\t\tawk 'BEGIN{FS=\"\\t\"; OFS=\"\\t\"}NR==1{print $0, \"diff\", \"total\", \"percent\"; next}{for(i=5;i<=NF;i++){if($i==\"0|1\" || $i==\"1|0\"){diff++}}print $0, diff, NF-4, diff/(NF-4); diff=0}' ../data/phased_cross_genotypes.txt > ../data/phased_cross_genotypes_diff_percent.txt\n",
    "\t\t\t\t\t# Let's check per cross segregation numbers\n",
    "\t\t\t\t\tcut -f1 ../data/phased_cross_genotypes_diff_percent.txt | uniq | awk 'NR==1{next}FNR==NR{chrarr[$1]++}FNR==1{for(i=5;i<=39;i++){namearr[i]=$i}next}{for(i=5;i<=39;i++){if($i==\"0|1\" || $i==\"1|0\"){countarr[namearr[i] \"_\" $1]++}}} END{printf(\"Cross\"); for(key in chrarr){printf(\"\\t%s\", key)} printf(\"\\tTotal\\n\"); for(cross in namearr){printf(\"%s\", namearr[cross]); for(key in chrarr){printf(\"\\t%s\", countarr[namearr[cross] \"_\" key]); tot=tot+countarr[namearr[cross] \"_\" key]}printf(\"\\t%s\\n\", tot); tot=0}}' - ../data/phased_cross_genotypes_diff_percent.txt > ../data/markers_per_cross_per_chr.txt\n",
    "\t\t\t\t\t# Copy the main file that might be of interest to the `res` directory\n",
    "\t\t\t\t\tcp -f ../data/phased_cross_genotypes_diff_percent.txt ../res/phased_cross_genotypes_diff_percent.txt\n",
    "\t\t\t\t\t```\n",
    "\n",
    "```{r plot_cross_chr_count}\n",
    "library(ggplot2)\n",
    "library(reshape2)\n",
    "library(dplyr)\n",
    "# Read in the markers per cross per chromosome\n",
    "temp_dat = read.table(file = '../data/markers_per_cross_per_chr.txt', header = TRUE, sep = '\\t')\n",
    "# Melt it\n",
    "temp_dat_melt = melt(subset(temp_dat, select = !colnames(temp_dat) == 'Total'), idvar = 'Cross', variable.name = 'Chromosome', value.name = 'SNP count')\n",
    "temp_dat_melt$Chromosome = factor(temp_dat_melt$Chromosome, levels=sort(levels(factor(temp_dat_melt$Chromosome))))\n",
    "temp_dat_melt = subset(temp_dat_melt, !grepl('scaffold', temp_dat_melt$Chromosome))\n",
    "# Plot it\n",
    "p = ggplot(temp_dat_melt, aes(x=Cross, y=`SNP count`)) + geom_point() + facet_wrap(.~Chromosome)\n",
    "p = p + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n",
    "p = p + ggtitle('SNPs segregating on each chromosome for each founding cross')\n",
    "print(p)\n",
    "temp_dat_melt %>% group_by(Chromosome) %>% summarize(mean=mean(`SNP count`))\n",
    "mean(temp_dat_melt$`SNP count`)\n",
    "pdf('../res/sites_per_chr_per_cross.pdf', height = 16, width = 24)\n",
    "print(p)\n",
    "dev.off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of putatitive SNPs segregating on each chromosome for each founding cross. Excluded scaffolds where a single marker segregated on two different scaffolds.\n",
    "\n",
    "### Percent segregating raw numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = read.table('../data/phased_cross_genotypes_diff_percent.txt', header = TRUE)\n",
    "library(tidyr)\n",
    "ggplot(dat, aes(x=percent)) + geom_histogram(bins = 20) + ggtitle('Count of SNPs segregating in percent of crosses')\n",
    "sixty_seg_dat = dat %>%\n",
    "\t  # filter(percent > 0.6) %>%\n",
    "\t  select(grep(\"CHROM|POS|REF|ALT|diff|total|percent\", colnames(dat), value = TRUE, invert = TRUE)) %>%\n",
    "\t    gather(\"pop\", \"geno\") %>%\n",
    "\t      group_by(pop, geno) %>%\n",
    "\t        count()\n",
    "\t# str(sixty_seg_dat)\n",
    "\tseg_sixty_seg_dat = subset(sixty_seg_dat, geno %in% c('1|0', '0|1'))\n",
    "\ttotal_counts = seg_sixty_seg_dat %>%\n",
    "\t\t  group_by(pop) %>%\n",
    "\t\t    summarise(n = sum(n))\n",
    "\t    total_counts$geno = 'total'\n",
    "\t    merged = rbind(total_counts, seg_sixty_seg_dat)\n",
    "\t    min_total = min(subset(merged, geno == 'total')$n)\n",
    "\t    p = ggplot(merged, aes(x=pop, y=n, colour = geno, shape=geno))\n",
    "\t    p = p + geom_point()\n",
    "\t    p = p + geom_abline(slope = 0, intercept = min_total)\n",
    "\t    p = p + theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))\n",
    "\t    p = p + expand_limits(y = 0)\n",
    "\t    p = p + ggtitle('Number of segregating sites in each cross')\n",
    "\t    print(p)\n",
    "\t    pdf('../res/sites_per_cross.pdf', height = 12, width = 8)\n",
    "\t    print(p)\n",
    "\t    dev.off()\n",
    "\t    ###\n",
    "\t    # Going to plot out positioning of markers\n",
    "\t    markers = dat\n",
    "\t    dat$gt_60 = dat$percent > 0.6\n",
    "\t    dat$gt_50 = dat$percent > 0.5\n",
    "\t    dat$gt_40 = dat$percent > 0.4\n",
    "\t    ```\n",
    "\n",
    "```{r, fig.height=12, fig.width=8}\n",
    "p = ggplot(dat, aes(x = POS, y = percent, colour=gt_40))\n",
    "p = p + expand_limits(y=0)\n",
    "p = p + facet_wrap(.~CHROM, ncol = 2)\n",
    "p = p + geom_point()\n",
    "print(p)\n",
    "pdf('../res/site_distribution_across_chr.pdf', height = 12, width = 8)\n",
    "print(p)\n",
    "dev.off()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
